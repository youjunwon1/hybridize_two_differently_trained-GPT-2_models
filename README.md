# hybridize_two_differently_trained-GPT-2_models
description of how to hybridize two differently trained GPT-2 models to create a new GPT-2 model (like dog breeding)
The possibility of crossbreeding GPT-2 models:

Model performance enhancement: By crossbreeding two models with different strengths, a new model with improved performance can be created.
Expansion of model diversity: Crossbreeding models trained with diverse datasets and hyperparameters can create new models with new features and characteristics.
Model exploration and optimization: Crossbreeding allows for the exploration of various model variations and the discovery of optimal model structures.

What if we bred only the good-natured ones or the ones sensitive to errors, continuously refining those traits?


The problem with AI right now is that there's this desire to flaunt its creations even if it's wrong. 
What if, among many AI models that have undergone various trainings, we could eventually breed a model that's willing to admit its mistakes? 
We could breed that one to gradually create a model that only speaks the truth, couldn't we?


GPT-2 모델 교배의 가능성:

모델 성능 향상: 서로 다른 강점을 가진 두 모델을 교배하여 더 나은 성능을 가진 새로운 모델을 만들 수 있습니다.
모델 다양성 확장: 다양한 학습 데이터와 하이퍼파라미터를 사용하여 훈련된 모델들을 교배하여 새로운 기능과 특성을 가진 모델을 만들 수 있습니다.
모델 탐색 및 최적화: 교배를 통해 다양한 모델 변형을 탐색하고 최적의 모델 구조를 찾을 수 있습니다.

강아지를 브리딩해서  착한 아이만  계속 브리딩해나가거나 
오류에 민감한 아이만 브리딩 해나간다면   어떨까  ?  

지금 ai의 문제는 자신이 틀려도 뭔가를 만들어 냈다는 것을 떠벌리고 싶어하는 녀석이란 말이야 
그거를  여러 트레이닝을 거친  ai들 중에서  그래도 그나마 틀림을 인정하는 모델이 나오면  
그 녀석을 브리딩해서  점점 옳은 것만 말하는 녀석을 만들 수 있지 않을까 ? 

